{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"token\")\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, token=hf_token, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "lc_folder = \"/kaggle/input/bil-471/LCs\"\n",
    "lc_files = [f for f in os.listdir(lc_folder) if f.endswith(\".json\")]\n",
    "\n",
    "def get_lc_name(filename):\n",
    "    return filename.split(\".\")[0].upper()\n",
    "\n",
    "lc_names = sorted(set(get_lc_name(f) for f in lc_files))\n",
    "\n",
    "all_questions = set()\n",
    "for file in lc_files:\n",
    "    with open(os.path.join(lc_folder, file), encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for q in data[\"questions\"]:\n",
    "            if q.strip() and \"öğrenci\" not in q.lower():\n",
    "                all_questions.add(q.strip())\n",
    "\n",
    "reference_answers = {}\n",
    "for q in sorted(all_questions):\n",
    "    prompt = f\"Aşağıdaki soruya kısa, açık ve doğru bir yanıt ver:\\n\\nSoru: {q}\\nCevap:\"\n",
    "    output = text_generator(prompt, max_new_tokens=100, temperature=0.2)[0][\"generated_text\"]\n",
    "    answer = output.split(\"Cevap:\")[-1].strip()\n",
    "    reference_answers[q] = answer\n",
    "\n",
    "reference_embeddings = {\n",
    "    q: embedding_model.encode(a) for q, a in reference_answers.items()\n",
    "}\n",
    "\n",
    "train_path = \"/kaggle/input/bil-471/processed_train_student.csv\"\n",
    "test_path = \"/kaggle/input/bil-471/processed_test_student.csv\"\n",
    "train_uids = pd.read_csv(train_path)[\"UID\"].astype(int).tolist()\n",
    "test_uids = pd.read_csv(test_path)[\"UID\"].astype(int).tolist()\n",
    "ref_uids = sorted(set(train_uids + test_uids))\n",
    "\n",
    "lc_uid_scores = {lc: {} for lc in lc_names}\n",
    "\n",
    "for file in lc_files:\n",
    "    lc_name = get_lc_name(file)\n",
    "    with open(os.path.join(lc_folder, file), encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        questions = data[\"questions\"]\n",
    "        for answer in data[\"answers\"]:\n",
    "            uid = int(answer[\"id\"])\n",
    "            sims = []\n",
    "            for i, q in enumerate(questions[1:], start=1):\n",
    "                cevap_key = f\"cevap{i}\"\n",
    "                student_answer = str(answer.get(cevap_key, \"\")).strip()\n",
    "                if not student_answer:\n",
    "                    continue\n",
    "                try:\n",
    "                    student_emb = embedding_model.encode(student_answer)\n",
    "                    ref_emb = reference_embeddings.get(q)\n",
    "                    if ref_emb is not None:\n",
    "                        sim = cosine_similarity([student_emb], [ref_emb])[0][0]\n",
    "                        sims.append(sim)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            mean_sim = sum(sims) / len(sims) if sims else 0\n",
    "            lc_uid_scores[lc_name][uid] = mean_sim\n",
    "\n",
    "result_rows = []\n",
    "for uid in ref_uids:\n",
    "    row = {\"UID\": int(uid)}\n",
    "    scores = []\n",
    "    for lc in lc_names:\n",
    "        score = lc_uid_scores[lc].get(int(uid), 0)\n",
    "        row[lc] = score\n",
    "        scores.append(score)\n",
    "    row[\"lc_similarity_mean\"] = sum(scores) / len(scores) if scores else 0\n",
    "    result_rows.append(row)\n",
    "\n",
    "result_df = pd.DataFrame(result_rows)\n",
    "result_df.to_csv(\"lc_similarity_full.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
